{"cells":[{"cell_type":"markdown","metadata":{"id":"X4XyoxFwL8Kv"},"source":["# Set Up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_u80XBl7ZMH"},"outputs":[],"source":["import sys\n","import os\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import pandas as pd\n","import torch.nn.functional as F\n","import torch.utils.data as Data\n","import csv\n","import scipy.io\n","import matplotlib.pyplot as plt\n","import scipy.stats\n","import random\n","import warnings\n","import glob\n","import matplotlib.ticker as mticker\n","from sklearn.model_selection import KFold, cross_val_score\n","from matplotlib.colors import LinearSegmentedColormap\n","from scipy.interpolate import interp1d\n","from scipy.stats import norm\n","from matplotlib.lines import Line2D\n","from tqdm import tqdm\n","from torch.autograd import Variable\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score\n","from matplotlib.pyplot import figure\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.linear_model import LinearRegression\n","from mlxtend.evaluate import ttest\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from scipy import stats\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.utils import resample\n","from sklearn.metrics import c_score\n","from matplotlib.ticker import PercentFormatter\n","from lifelines import KaplanMeierFitter\n","from lifelines.utils import qth_survival_times\n","from lifelines.statistics import logrank_test\n","from lifelines import KaplanMeierFitter\n","from sklearn.calibration import calibration_curve\n","from matplotlib import rcParams"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lv01Wjq62C73"},"outputs":[],"source":["def compute_midrank(x):\n","   J = np.argsort(x)\n","   Z = x[J]\n","   N = len(x)\n","   T = np.zeros(N, dtype=np.float64)\n","   i = 0\n","   while i < N:\n","       j = i\n","       while j < N and Z[j] == Z[i]:\n","           j += 1\n","       T[i:j] = 0.5*(i + j - 1)\n","       i = j\n","   T2 = np.empty(N, dtype=np.float64)\n","   T2[J] = T + 1\n","   return T2\n","\n","def compute_midrank_weight(x, sample_weight):\n","   J = np.argsort(x)\n","   Z = x[J]\n","   cumulative_weight = np.cumsum(sample_weight[J])\n","   N = len(x)\n","   T = np.zeros(N, dtype=np.float64)\n","   i = 0\n","   while i < N:\n","       j = i\n","       while j < N and Z[j] == Z[i]:\n","           j += 1\n","       T[i:j] = cumulative_weight[i:j].mean()\n","       i = j\n","   T2 = np.empty(N, dtype=np.float64)\n","   T2[J] = T\n","   return T2\n","\n","def fastDeLong(predictions_sorted_transposed, label_1_count, sample_weight=None):\n","   if sample_weight is None:\n","       return fastDeLong_no_weights(predictions_sorted_transposed, label_1_count)\n","   else:\n","       return fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight)\n","\n","def fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight):\n","   m = label_1_count\n","   n = predictions_sorted_transposed.shape[1] - m\n","   positive_examples = predictions_sorted_transposed[:, :m]\n","   negative_examples = predictions_sorted_transposed[:, m:]\n","   k = predictions_sorted_transposed.shape[0]\n","   tx = np.empty([k, m], dtype=np.float64)\n","   ty = np.empty([k, n], dtype=np.float64)\n","   tz = np.empty([k, m + n], dtype=np.float64)\n","   for r in range(k):\n","       tx[r, :] = compute_midrank_weight(positive_examples[r, :], sample_weight[:m])\n","       ty[r, :] = compute_midrank_weight(negative_examples[r, :], sample_weight[m:])\n","       tz[r, :] = compute_midrank_weight(predictions_sorted_transposed[r, :], sample_weight)\n","   total_positive_weights = sample_weight[:m].sum()\n","   total_negative_weights = sample_weight[m:].sum()\n","   pair_weights = np.dot(sample_weight[:m, np.newaxis], sample_weight[np.newaxis, m:])\n","   total_pair_weights = pair_weights.sum()\n","   aucs = (sample_weight[:m]*(tz[:, :m] - tx)).sum(axis=1) / total_pair_weights\n","   v01 = (tz[:, :m] - tx[:, :]) / total_negative_weights\n","   v10 = 1. - (tz[:, m:] - ty[:, :]) / total_positive_weights\n","   sx = np.cov(v01)\n","   sy = np.cov(v10)\n","   delongcov = sx / m + sy / n\n","   return aucs, delongcov\n","\n","def fastDeLong_no_weights(predictions_sorted_transposed, label_1_count):\n","   m = label_1_count\n","   n = predictions_sorted_transposed.shape[1] - m\n","   positive_examples = predictions_sorted_transposed[:, :m]\n","   negative_examples = predictions_sorted_transposed[:, m:]\n","   k = predictions_sorted_transposed.shape[0]\n","   tx = np.empty([k, m], dtype=np.float64)\n","   ty = np.empty([k, n], dtype=np.float64)\n","   tz = np.empty([k, m + n], dtype=np.float64)\n","   for r in range(k):\n","       tx[r, :] = compute_midrank(positive_examples[r, :])\n","       ty[r, :] = compute_midrank(negative_examples[r, :])\n","       tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n","   aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n","   v01 = (tz[:, :m] - tx[:, :]) / n\n","   v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n","   sx = np.cov(v01)\n","   sy = np.cov(v10)\n","   delongcov = sx / m + sy / n\n","   return aucs, delongcov\n","\n","def calc_pvalue(aucs, sigma):\n","   l = np.array([[1, -1]])\n","   z = np.abs(np.diff(aucs)) / (np.sqrt(np.dot(np.dot(l, sigma), l.T)) + 1e-8)\n","   pvalue = 2 * (1 - scipy.stats.norm.cdf(np.abs(z)))\n","   return pvalue\n","\n","def compute_ground_truth_statistics(ground_truth, sample_weight=None):\n","   assert np.array_equal(np.unique(ground_truth), [0, 1])\n","   order = (-ground_truth).argsort()\n","   label_1_count = int(ground_truth.sum())\n","   if sample_weight is None:\n","       ordered_sample_weight = None\n","   else:\n","       ordered_sample_weight = sample_weight[order]\n","   return order, label_1_count, ordered_sample_weight\n","\n","def delong_roc_variance(ground_truth, predictions):\n","   sample_weight = None\n","   order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(\n","       ground_truth, sample_weight)\n","   predictions_sorted_transposed = predictions[np.newaxis, order]\n","   aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n","   assert len(aucs) == 1,\n","   return aucs[0], delongcov\n","\n","def delong_roc_test(ground_truth, predictions_one, predictions_two):\n","   sample_weight = None\n","   order, label_1_count,ordered_sample_weight = compute_ground_truth_statistics(ground_truth)\n","   predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n","   aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count,sample_weight)\n","   return calc_pvalue(aucs, delongcov)\n","\n","def delong_roc_ci(y_true,y_pred):\n","   aucs, auc_cov = delong_roc_variance(y_true, y_pred)\n","   auc_std = np.sqrt(auc_cov)\n","   lower_upper_q = np.abs(np.array([0, 1]) - (1 - 0.95) / 2) # alpha=0.95\n","   ci = stats.norm.ppf(\n","       lower_upper_q,\n","       loc=aucs,\n","       scale=auc_std)\n","   ci[ci > 1] = 1\n","   return aucs,ci"]},{"cell_type":"markdown","metadata":{"id":"Eg5mbbuhsIRr"},"source":["# Main analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1FQaXuNAl8c"},"outputs":[],"source":["path0='/UKB协变量_ysp20230503.dta'\n","path1='/UKB代谢组_ysp20230429.dta'\n","path2='/UKB心血管结局_ysp20230429.dta'\n","path3='/UKB_dmstatus.dta'\n","\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1', 'a2', 'a6',  'a8', 'a13','a16','chol_mmol','hdl']]\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG5yC3rq8WRY"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5FWbnZ9Al8d"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]\n","c_table = pd.DataFrame()\n","color_map=['#C6B69D','#A19275','#949496','#DFDCD7','#828B78','#7C785D','#D4CBAC','#EBDBA7','#B27F9E','#B1764C']\n","conv=['a1', 'a2', 'a6',  'a8', 'a13','a16','chol_mmol','hdl', 'dmstatus','rnfl']\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  plt.figure(figsize=(5,5))\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(convar,dm, on='eid_ageing')\n","  merged_df = pd.merge(merged_df,metab, on='eid_ageing')\n","  merged_df = pd.merge(merged_df,disease, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  test_ratio=0.2\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  for j in range(10):\n","\n","    x_train_1 = train_data.iloc[:, j]\n","    y_train_1 = train_data.iloc[:, -1]\n","    x_test_1 = test_data.iloc[:, j]\n","    y_test_1 = test_data.iloc[:, -1]\n","    xtrain1 = x_train_1.to_numpy()\n","    ytrain1 = y_train_1.to_numpy()\n","    xtest1 = x_test_1.to_numpy()\n","    ytest1 = y_test_1.to_numpy()\n","\n","    rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_1.fit(xtrain1, ytrain1)\n","    ypred1 = rf_1.predict(xtest1)\n","    fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","    c1 = auc(fpr1, tpr1)\n","\n","    # Results\n","    c_table.loc[i, j] = c1\n","    col_name = disease.columns[1]\n","    arr_path = ('/results/auc/ypred1_'+f\"{col_name}\" +'.npy')\n","    np.save(arr_path, ypred1)\n","    color = color_map[j]\n","    label = conv[j]+' (area = %0.3f)' % c1\n","    plt.plot(fpr1, tpr1, color=color, lw=1, label=label)\n","\n","  plt.plot([0, 1], [0, 1], color='#E1DCD9', lw=1, linestyle='--')\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.title('roc_curve_' +f\"{col_name}\")\n","  plt.legend(loc=\"lower right\")\n","  plt.savefig('/results/roc_curve_' +f\"{col_name}\" + '.png')\n","  plt.clf()\n","\n","  arr_path = ('ytest_'+f\"{col_name}\" + '.npy')\n","  np.save(arr_path, ytest1)\n","\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"Y7WNFVm35JmE"},"source":["## Models Comparison (Simple Model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dzDVaRfD5JmQ"},"outputs":[],"source":["# Load data\n","path0='/UKB协变量_ysp20230503.dta'\n","path1='/UKB代谢组_ysp20230429.dta'\n","path2='/UKB心血管结局_ysp20230429.dta'\n","path3='/UKB_dmstatus.dta'\n","\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvG3pVN15JmQ"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwjQl2Mq5JmR"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]\n","c_table = pd.DataFrame(columns=['RF_CB', 'RF_SB', 'RF_RNFL', 'P-value'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  test_ratio=0.2\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  x_train_1 = train_data.iloc[:, :-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, :-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  train_data_2 = train_data.iloc[:, :2]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, :2]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  x_train_3 = train_data.iloc[:, 2:-1]\n","  y_train_3 = train_data.iloc[:, -1]\n","  x_test_3 = test_data.iloc[:, 2:-1]\n","  y_test_3 = test_data.iloc[:, -1]\n","  xtrain3 = x_train_3.to_numpy()\n","  ytrain3 = y_train_3.to_numpy()\n","  xtest3 = x_test_3.to_numpy()\n","  ytest3 = y_test_3.to_numpy()\n","  rf_3 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_3.fit(xtrain3, ytrain3)\n","  ypred3 = rf_3.predict(xtest3)\n","  fpr3, tpr3, _ = roc_curve(ytest3, ypred3)\n","  c3 = auc(fpr3, tpr3)\n","\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  c_table.loc[len(c_table)] = [c1, c2, c3, p]\n","  col_name = disease.columns[1]\n","\n","\n","  arr_path = ('ypred1_'+f\"{col_name}\" +'.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_'+f\"{col_name}\" +'.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ypred3_'+f\"{col_name}\" +'.npy')\n","  np.save(arr_path, ypred3)\n","  arr_path = ('ytest_'+f\"{col_name}\" +'.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"5Kw7EXLLSALD"},"source":["## Models Comparison (FGCRS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3tH5O9USl7G"},"outputs":[],"source":["# Load data\n","path0='/UKB协变量_ysp20230503.dta'\n","path1='/UKB代谢组_ysp20230429.dta'\n","path2='/UKB心血管结局_ysp20230429.dta'\n","path3='/UKB_dmstatus.dta'\n","\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a6','a16','a13','chol_mmol','hdl']]\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9mC5dFE0TJaM"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMWgom3BSALJ"},"outputs":[],"source":["event = event[['eid_ageing','t2d_2104','mi_2104','cvddeath_status','cvd_hf_2104','cerestroke_2104','deathstatus']]\n","c_table = pd.DataFrame(columns=['CB_CIL', 'CB_ROC', 'CB_CIH', 'CV_CIL', 'CV_ROC', 'CV_CIH', 'P'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  # Combined Model\n","  age_idx = train_data.columns.get_loc('a1')\n","  x_train_1 = train_data.iloc[:, age_idx:-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, age_idx:-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  metab_idx = train_data.columns.get_loc('m7')\n","  train_data_2 = train_data.iloc[:, age_idx:metab_idx]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, age_idx:metab_idx]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  # Results\n","  c_table.loc[len(c_table)] = [ci1[0], aus1, ci1[1], ci2[0], aus2, ci2[1], p[0,0]]\n","  col_name = disease.columns[1]\n","\n","\n","\n","  arr_path = ('ypred1_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ytest_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"w7nhG1vNUdbY"},"source":["## FGCRS T2D Model (Supplementary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LF9ftrPqVedn"},"outputs":[],"source":["# Load data\n","path0='UKB协变量T2D_ysp20230718.dta'\n","path1='UKB心血管结局_ysp20230429.dta'\n","path2='UKB代谢组_ysp20230429.dta'\n","convar=pd.read_stata(path0)\n","event=pd.read_stata(path1)\n","metab=pd.read_stata(path2)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PbG1G6Q6zuo"},"outputs":[],"source":["scaler = MinMaxScaler()\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])\n","\n","# Build conventional model\n","concise = convar[['eid_ageing','baselineage','sex','family_diabetes','bmi','hba1c']]\n","full = convar[['eid_ageing','baselineage','sex','family_diabetes','bmi','hba1c','hbp','hdl','tg','waist']]"]},{"cell_type":"markdown","metadata":{"id":"_I_GO1jQ-Q03"},"source":["### Model Comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ar2I5oD42gQ5"},"outputs":[],"source":["# Model Training\n","event = event[['eid_ageing','t2d_2104']]\n","models = ['concise','full']\n","c_table = pd.DataFrame(columns=['RF_CB', 'RF_FGCRS', 'P-value'])\n","\n","for i in tqdm(range(2)):\n","\n","  model_name = models[i]\n","\n","  if i==0:  #concise model\n","    merged_df = pd.merge(metab,event, on='eid_ageing')\n","    merged_df = pd.merge(concise,merged_df, on='eid_ageing')\n","    merged_df = merged_df.dropna()\n","    df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  if i==1:  #full model\n","    merged_df = pd.merge(metab,event, on='eid_ageing')\n","    merged_df = pd.merge(full,merged_df, on='eid_ageing')\n","    merged_df = merged_df.dropna()\n","    df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  test_ratio=0.2\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  # Combined Model\n","  x_train_1 = train_data.iloc[:, :-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, :-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  train_data_2 = train_data.iloc[:, :-27]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, :-27]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  # Results\n","  c_table.loc[len(c_table)] = [c1, c2, p]\n","\n","\n","  arr_path = ('ypred1_t2d_'+f\"{model_name}\"+ '.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_t2d_'+f\"{model_name}\"+ '.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ytest_t2d_'+f\"{model_name}\"+ '.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"zsQ7WIq6O9PB"},"source":["### Stratified Study  (Sex)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ow-1Up-DO8F6"},"outputs":[],"source":["event = event[['eid_ageing','t2d_2104']]\n","c_table = pd.DataFrame(columns=['RF_CB', 'RF_FGCRS', 'P-value'])\n","\n","# if need to balance dataset\n","balance = 0\n","\n","merged_df = pd.merge(metab,event, on='eid_ageing')\n","merged_df = pd.merge(full,merged_df, on='eid_ageing')\n","merged_df = merged_df.dropna()\n","df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","for j in tqdm(range(2)):\n","  sex = df_shuffled.loc[df_shuffled['sex'] == j]\n","  sex.drop(['sex'], axis=1, inplace=True)\n","\n","  train_ratio=0.8\n","  test_ratio=0.2\n","  num_train_samples = int(len(sex) * train_ratio)\n","  num_test_samples = len(sex) - num_train_samples\n","  train_data = sex[:num_train_samples].reset_index(drop=True)\n","  test_data = sex[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  if balance == 1:\n","\n","    female = len(df_shuffled.loc[df_shuffled['sex'] == 0])\n","    male = len(df_shuffled.loc[df_shuffled['sex'] == 1])\n","\n","    if male > female and j==0:\n","      indexlist = list(range(1,int(female*0.8)))\n","      random.seed(100)\n","      oversample = np.array(random.sample(indexlist, k=int((male-female)*0.8)))\n","      aug = train_data.iloc[oversample, :]\n","      train_data = pd.concat([train_data, aug], axis=0)\n","\n","    if female >= male and j==1:\n","      indexlist = list(range(1,int(male*0.8)))\n","      random.seed(100)\n","      oversample = np.array(random.sample(indexlist, k=int((female-male)*0.8)))\n","      aug = train_data.iloc[oversample, :]\n","      train_data = pd.concat([train_data, aug], axis=0)\n","\n","  # Combined Model\n","  x_train_1 = train_data.iloc[:, :-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, :-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  train_data_2 = train_data.iloc[:, :-27]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, :-27]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  c_table.loc[len(c_table)] = [c1, c2, p]\n","\n","\n","\n","  arr_path = ('ypred1_t2d_'+ str(j)+ '.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('auc/ypred2_t2d_'+ str(j)+ '.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ytest_t2d_'+ str(j) + '.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"J7qfKjc0TlMD"},"source":["### Stratified Study  (Edu)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwyhv2ulTpB2"},"outputs":[],"source":["path3='UKB协变量_ysp20230503.dta'\n","convar2 = pd.read_stata(path3)\n","convar2 = convar2[['eid_ageing','a9']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdEafT9sWvdP"},"outputs":[],"source":["event = event[['eid_ageing','t2d_2104']]\n","c_table = pd.DataFrame(columns=['RF_CB', 'RF_FGCRS', 'P-value'])\n","\n","merged_df = pd.merge(metab,event, on='eid_ageing')\n","merged_df = pd.merge(full,merged_df, on='eid_ageing')\n","merged_df = pd.merge(convar2,merged_df, on='eid_ageing')\n","merged_df = merged_df.dropna()\n","df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","for j in tqdm(range(2)):\n","  edu = df_shuffled.loc[df_shuffled['a9'] == j]\n","  edu.drop(['a9'], axis=1, inplace=True)\n","\n","  train_ratio=0.8\n","  test_ratio=0.2\n","  num_train_samples = int(len(edu) * train_ratio)\n","  num_test_samples = len(edu) - num_train_samples\n","  train_data = edu[:num_train_samples].reset_index(drop=True)\n","  test_data = edu[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  # Combined Model\n","  x_train_1 = train_data.iloc[:, :-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, :-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  train_data_2 = train_data.iloc[:, :-27]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, :-27]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  c_table.loc[len(c_table)] = [c1, c2, p]\n","\n","  plt.figure(figsize=(5,5))\n","  plt.plot(fpr1, tpr1, color='#50A0C3', lw=1, label='FGCRS+RNFL (area = %0.3f)' % c1)\n","  plt.plot(fpr2, tpr2, color='#F8981D', lw=1, label='FGCRS (area = %0.3f)' % c2)\n","  plt.plot([0, 1], [0, 1], color='#E1DCD9', lw=1, linestyle='--')\n","  t = ('p-value = %0.3f' % p)\n","  plt.text(0,1,t)\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.title('roc_curve_t2d_'+ str(j))\n","  plt.legend(loc=\"lower right\")\n","  plt.savefig('roc_curve_t2d_' + str(j)+ '.png')\n","  plt.clf()\n","\n","  arr_path = ('ypred1_t2d_'+ str(j)+ '.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_t2d_'+ str(j)+ '.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ytest_t2d_'+ str(j) + '.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"ZvP_E36tTnLy"},"source":["### Stratified Study  (Social)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPzQcvoSUUI2"},"outputs":[],"source":["path3='UKB协变量_ysp20230503.dta'\n","convar2 = pd.read_stata(path3)\n","convar2 = convar2[['eid_ageing','a5']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KR6pNea3YKkQ"},"outputs":[],"source":["event = event[['eid_ageing','t2d_2104']]\n","c_table = pd.DataFrame(columns=['RF_CB', 'RF_FGCRS', 'P-value'])\n","\n","merged_df = pd.merge(metab,event, on='eid_ageing')\n","merged_df = pd.merge(full,merged_df, on='eid_ageing')\n","merged_df = pd.merge(convar2,merged_df, on='eid_ageing')\n","merged_df = merged_df.dropna()\n","df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","for j in tqdm(range(2)):\n","  townsend = df_shuffled.loc[df_shuffled['a5'] == j]\n","  townsend.drop(['a5'], axis=1, inplace=True)\n","\n","  train_ratio=0.8\n","  test_ratio=0.2\n","  num_train_samples = int(len(townsend) * train_ratio)\n","  num_test_samples = len(townsend) - num_train_samples\n","  train_data = townsend[:num_train_samples].reset_index(drop=True)\n","  test_data = townsend[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  # Combined Model\n","  x_train_1 = train_data.iloc[:, :-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, :-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  train_data_2 = train_data.iloc[:, :-27]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, :-27]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  c_table.loc[len(c_table)] = [c1, c2, p]\n","\n","  arr_path = ('ypred1_t2d_'+ str(j)+ '.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_t2d_'+ str(j)+ '.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ytest_t2d_'+ str(j) + '.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"any-3tLyNb1Z"},"source":["## Model Comparison (SCORE2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_nh_oBuT1gl"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a6','a16','chol_mmol','hdl']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLtImMwXVO7J"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpUZr_Y4NvEH"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzBRtPqDNzLA"},"outputs":[],"source":["c_table = pd.DataFrame(columns=['RF_CB', 'RF_SCORE2', 'RF_RNFL','P-value'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbqB6eAON0lf"},"outputs":[],"source":["for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  test_ratio=0.2\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  # Combined Model\n","  x_train_1 = train_data.iloc[:, :-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, :-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  train_data_2 = train_data.iloc[:, :14]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, :14]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  # RNFL\n","  x_train_3 = train_data.iloc[:, 14:-2]\n","  y_train_3 = train_data.iloc[:, -1]\n","  x_test_3 = test_data.iloc[:, 14:-2]\n","  y_test_3 = test_data.iloc[:, -1]\n","\n","  xtrain3 = x_train_3.to_numpy()\n","  ytrain3 = y_train_3.to_numpy()\n","  xtest3 = x_test_3.to_numpy()\n","  ytest3 = y_test_3.to_numpy()\n","\n","  rf_3 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_3.fit(xtrain3, ytrain3)\n","  ypred3 = rf_3.predict(xtest3)\n","  fpr3, tpr3, _ = roc_curve(ytest3, ypred3)\n","  c3 = auc(fpr3, tpr3)\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  # Results\n","  c_table.loc[len(c_table)] = [c1, c2, c3, p]\n","  col_name = disease.columns[1]\n","\n","\n","  arr_path = ('ypred1_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ypred3_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred3)\n","  arr_path = ('ytest_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"xhD5sanvjfQO"},"source":["## Model Comparison (AHA/ASCVD)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bq6a-28OjfQa"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a6','a8','a13','a16','chol_mmol','hdl']]\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7VV28u7jfQa"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LH0KJTizKG_o"},"outputs":[],"source":["event = event[['eid_ageing','t2d_2104']] #,'mi_2104','cvddeath_status','cvd_hf_2104','cerestroke_2104','deathstatus'\n","c_table = pd.DataFrame(columns=['CB_CIL', 'CB_ROC', 'CB_CIH', 'CV_CIL', 'CV_ROC', 'CV_CIH', 'P'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  #merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  # Combined Model\n","  age_idx = train_data.columns.get_loc('a1')\n","  x_train_1 = train_data.iloc[:, age_idx:-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, age_idx:-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  metab_idx = train_data.columns.get_loc('m7')\n","  train_data_2 = train_data.iloc[:, age_idx:metab_idx]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, age_idx:metab_idx]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  # Results\n","  c_table.loc[len(c_table)] = [ci1[0], aus1, ci1[1], ci2[0], aus2, ci2[1], p[0,0]]\n","  col_name = disease.columns[1]\n","\n","  arr_path = ('ypred1_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ytest_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"BUKfagQpmOmo"},"source":["## Model Comparison (WHO-CVD)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Jx2a9YCmOmz"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a6','a16','chol_mmol']]\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDA57TyqmOmz"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClMqP79ZJLFw"},"outputs":[],"source":["event = event[['eid_ageing','t2d_2104']] #,'mi_2104','cvddeath_status','cvd_hf_2104','cerestroke_2104','deathstatus'\n","c_table = pd.DataFrame(columns=['CB_CIL', 'CB_ROC', 'CB_CIH', 'CV_CIL', 'CV_ROC', 'CV_CIH', 'P'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  #merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","  train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","  test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","  # Combined Model\n","  age_idx = train_data.columns.get_loc('a1')\n","  x_train_1 = train_data.iloc[:, age_idx:-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, age_idx:-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","  fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","  c1 = auc(fpr1, tpr1)\n","\n","  # FGCRS\n","  metab_idx = train_data.columns.get_loc('m7')\n","  train_data_2 = train_data.iloc[:, age_idx:metab_idx]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, age_idx:metab_idx]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","  fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","  c2 = auc(fpr2, tpr2)\n","\n","  #Delong Test\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","  # Results\n","  c_table.loc[len(c_table)] = [ci1[0], aus1, ci1[1], ci2[0], aus2, ci2[1], p[0,0]]\n","  col_name = disease.columns[1]\n","\n","\n","  arr_path = ('ypred1_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('ypred2_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('ytest_'+f\"{col_name}_\" +'.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"jUX5HAWHPifR"},"source":["## Stratified Study (Sex)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBrY1PbyPifb"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a6','a16','a13','chol_mmol','hdl']]\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kb0hY2JDCPNC"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eq4N6r4jPifb"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]"]},{"cell_type":"markdown","metadata":{"id":"h_RXw1Jm4Ub9"},"source":["Population"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaOQ-C2P4Xvn"},"outputs":[],"source":["disease = ['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']\n","population = pd.DataFrame(columns=['female','female_disease','female_ratio','male','male_disease','male_ratio'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  # balance edu dataset\n","  nonuniv = df_shuffled.loc[df_shuffled['a2'] == 0]\n","  univ = df_shuffled.loc[df_shuffled['a2'] == 1]\n","  nonuniv_r = nonuniv[nonuniv.iloc[:, -1] == 1]\n","  univ_r = univ[univ.iloc[:, -1] == 1]\n","\n","  x1 = len(nonuniv)\n","  x2 = len(univ)\n","  x3 = len(nonuniv_r)\n","  x4 = len(univ_r)\n","  r1 = x3/x1\n","  r2 = x4/x2\n","\n","  population.loc[len(population)] = [x1,x3,r1,x2,x4,r2]\n","\n","population.to_csv('population.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"-7hQmbzI4WFC"},"source":["Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1wqL-skPifc"},"outputs":[],"source":["c_table = pd.DataFrame(columns=['RF_CB', 'RF_FGCRS', 'P-value'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uztc3t1HPifc"},"outputs":[],"source":["for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  # balance sex dataset\n","  female = len(df_shuffled.loc[df_shuffled['a2'] == 0])\n","  male = len(df_shuffled.loc[df_shuffled['a2'] == 1])\n","\n","  for j in range(2):\n","    sex = df_shuffled.loc[df_shuffled['a2'] == j]\n","    sex.drop(['a2'], axis=1, inplace=True)\n","\n","    train_ratio=0.8\n","    test_ratio=0.2\n","    num_train_samples = int(len(sex) * train_ratio)\n","    num_test_samples = len(sex) - num_train_samples\n","    train_data = sex[:num_train_samples].reset_index(drop=True)\n","    test_data = sex[num_train_samples:].reset_index(drop=True)\n","    train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","    test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","    if male > female and j==0:\n","      indexlist = list(range(1,int(female*0.8)))\n","      random.seed(100)\n","      oversample = np.array(random.sample(indexlist, k=int((male-female)*0.8)))\n","      aug = train_data.iloc[oversample, :]\n","      train_data = pd.concat([train_data, aug], axis=0)\n","\n","    if female >= male and j==1:\n","      indexlist = list(range(1,int(male*0.8)))\n","      random.seed(100)\n","      oversample = np.array(random.sample(indexlist, k=int((female-male)*0.8)))\n","      aug = train_data.iloc[oversample, :]\n","      train_data = pd.concat([train_data, aug], axis=0)\n","\n","\n","    # Combined Model\n","    x_train_1 = train_data.iloc[:, :-1]\n","    y_train_1 = train_data.iloc[:, -1]\n","    x_test_1 = test_data.iloc[:, :-1]\n","    y_test_1 = test_data.iloc[:, -1]\n","    xtrain1 = x_train_1.to_numpy()\n","    ytrain1 = y_train_1.to_numpy()\n","    xtest1 = x_test_1.to_numpy()\n","    ytest1 = y_test_1.to_numpy()\n","\n","    rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_1.fit(xtrain1, ytrain1)\n","    ypred1 = rf_1.predict(xtest1)\n","    fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","    c1 = auc(fpr1, tpr1)\n","\n","    # FGCRS\n","    train_data_2 = train_data.iloc[:, :15]\n","    train_label_2 = train_data.iloc[:, -1]\n","    test_data_2 = test_data.iloc[:, :15]\n","    test_label_2 = test_data.iloc[:, -1]\n","    train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","    test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","    x_train_2 = train_data_2.iloc[:, :-1]\n","    y_train_2 = train_data_2.iloc[:, -1]\n","    x_test_2 = test_data_2.iloc[:, :-1]\n","    y_test_2 = test_data_2.iloc[:, -1]\n","    xtrain2 = x_train_2.to_numpy()\n","    ytrain2 = y_train_2.to_numpy()\n","    xtest2 = x_test_2.to_numpy()\n","    ytest2 = y_test_2.to_numpy()\n","\n","    rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_2.fit(xtrain2, ytrain2)\n","    ypred2 = rf_2.predict(xtest2)\n","    fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","    c2 = auc(fpr2, tpr2)\n","\n","    #Delong Test\n","    p = delong_roc_test(ytest1,ypred1,ypred2)\n","    aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","    aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","    # Results\n","    c_table.loc[len(c_table)] = [c1, c2, p]\n","    col_name = disease.columns[1]\n","\n","\n","    arr_path = ('ypred1_'+f\"{col_name}_\" + str(j) +'.npy')\n","    np.save(arr_path, ypred1)\n","    arr_path = ('ypred2_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ypred2)\n","    arr_path = ('ytest_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"3FYmdNy6EHoA"},"source":["## Stratified Study (Education)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKaZ5CNwEHoG"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a9','a6','a16','a13','chol_mmol','hdl']] #education index\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njHt36cai5Sn"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTjfq9NAEHoH"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]"]},{"cell_type":"markdown","metadata":{"id":"QbU9vL3otH2w"},"source":["population"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42EACDeFtMRb"},"outputs":[],"source":["disease = ['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']\n","population = pd.DataFrame(columns=['nonuniv','nonuniv_disease','nonuniv_ratio','univ','univ_disease','univ_ratio'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  # balance edu dataset\n","  nonuniv = df_shuffled.loc[df_shuffled['a9'] == 0]\n","  univ = df_shuffled.loc[df_shuffled['a9'] == 1]\n","  nonuniv_r = nonuniv[nonuniv.iloc[:, -1] == 1]\n","  univ_r = univ[univ.iloc[:, -1] == 1]\n","\n","  x1 = len(nonuniv)\n","  x2 = len(univ)\n","  x3 = len(nonuniv_r)\n","  x4 = len(univ_r)\n","  r1 = x3/x1\n","  r2 = x4/x2\n","\n","  population.loc[len(population)] = [x1,x3,r1,x2,x4,r2]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g4-YkAbTEHoH"},"outputs":[],"source":["c_table = pd.DataFrame(columns=['CB_CIL', 'CB_ROC', 'CB_CIH', 'CV_CIL', 'CV_ROC', 'CV_CIH', 'P'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  # balance edu dataset\n","  nonuniv = len(df_shuffled.loc[df_shuffled['a9'] == 0])\n","  univ = len(df_shuffled.loc[df_shuffled['a9'] == 1])\n","\n","  for j in range(2):\n","    edu = df_shuffled.loc[df_shuffled['a9'] == j]\n","    edu.drop(['a9'], axis=1, inplace=True)\n","\n","    # undersample\n","    if univ > nonuniv and j==1:\n","      edu = edu[:nonuniv].reset_index(drop=True)\n","\n","    if nonuniv >= univ and j==0:\n","      edu = edu[:univ].reset_index(drop=True)\n","\n","    train_ratio=0.8\n","    num_train_samples = int(len(edu) * train_ratio)\n","    num_test_samples = len(edu) - num_train_samples\n","    train_data = edu[:num_train_samples].reset_index(drop=True)\n","    test_data = edu[num_train_samples:].reset_index(drop=True)\n","    train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","    test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","    # Combined Model\n","    age_idx = train_data.columns.get_loc('a1')\n","    x_train_1 = train_data.iloc[:, age_idx:-1]\n","    y_train_1 = train_data.iloc[:, -1]\n","    x_test_1 = test_data.iloc[:, age_idx:-1]\n","    y_test_1 = test_data.iloc[:, -1]\n","    xtrain1 = x_train_1.to_numpy()\n","    ytrain1 = y_train_1.to_numpy()\n","    xtest1 = x_test_1.to_numpy()\n","    ytest1 = y_test_1.to_numpy()\n","\n","    rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_1.fit(xtrain1, ytrain1)\n","    ypred1 = rf_1.predict(xtest1)\n","    fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","    c1 = auc(fpr1, tpr1)\n","\n","    # FGCRS\n","    metab_idx = train_data.columns.get_loc('m7')\n","    train_data_2 = train_data.iloc[:, age_idx:metab_idx]\n","    train_label_2 = train_data.iloc[:, -1]\n","    test_data_2 = test_data.iloc[:, age_idx:metab_idx]\n","    test_label_2 = test_data.iloc[:, -1]\n","    train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","    test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","    x_train_2 = train_data_2.iloc[:, :-1]\n","    y_train_2 = train_data_2.iloc[:, -1]\n","    x_test_2 = test_data_2.iloc[:, :-1]\n","    y_test_2 = test_data_2.iloc[:, -1]\n","    xtrain2 = x_train_2.to_numpy()\n","    ytrain2 = y_train_2.to_numpy()\n","    xtest2 = x_test_2.to_numpy()\n","    ytest2 = y_test_2.to_numpy()\n","\n","    rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_2.fit(xtrain2, ytrain2)\n","    ypred2 = rf_2.predict(xtest2)\n","    fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","    c2 = auc(fpr2, tpr2)\n","\n","    #Delong Test\n","    p = delong_roc_test(ytest1,ypred1,ypred2)\n","    aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","    aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","    # Results\n","    c_table.loc[len(c_table)] = [ci1[0], aus1, ci1[1], ci2[0], aus2, ci2[1], p[0,0]]\n","\n","    col_name = disease.columns[1]\n","\n","    arr_path = ('ypred1_'+f\"{col_name}_\" + str(j) +'.npy')\n","    np.save(arr_path, ypred1)\n","    arr_path = ('ypred2_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ypred2)\n","    arr_path = ('ytest_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"8JFl_UdrW80Z"},"source":["## Stratified Study (Social)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ee5hXhzfW80j"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a5','a6','a16','a13','chol_mmol','hdl']] #a5 townsend depreviation index\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwlMtImMxBYD"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"markdown","metadata":{"id":"nw2CauiB2yZt"},"source":["Population"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QzMGljaT3qo8"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dw0bQqkQ21ZG"},"outputs":[],"source":["disease = ['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']\n","population = pd.DataFrame(columns=['well','well_disease','well_ratio','poor','poor_disease','poor_ratio'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  # balance edu dataset\n","  nonuniv = df_shuffled.loc[df_shuffled['a5'] == 0]\n","  univ = df_shuffled.loc[df_shuffled['a5'] == 1]\n","  nonuniv_r = nonuniv[nonuniv.iloc[:, -1] == 1]\n","  univ_r = univ[univ.iloc[:, -1] == 1]\n","\n","  x1 = len(nonuniv)\n","  x2 = len(univ)\n","  x3 = len(nonuniv_r)\n","  x4 = len(univ_r)\n","  r1 = x3/x1\n","  r2 = x4/x2\n","\n","  population.loc[len(population)] = [x1,x3,r1,x2,x4,r2]\n","\n","population.to_csv('population.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"UxeCw5sf22pE"},"source":["Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hpah8xn0aMjE"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]\n","c_table = pd.DataFrame(columns=['RF_CB', 'RF_FGCRS','P-value'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  for j in range(2):\n","    townsend = df_shuffled.loc[df_shuffled['a5'] == j]\n","    townsend.drop(['a5'], axis=1, inplace=True)\n","\n","    train_ratio=0.8\n","    test_ratio=0.2\n","    num_train_samples = int(len(townsend) * train_ratio)\n","    num_test_samples = len(townsend) - num_train_samples\n","    train_data = townsend[:num_train_samples].reset_index(drop=True)\n","    test_data = townsend[num_train_samples:].reset_index(drop=True)\n","    train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","    test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","    # Combined Model\n","    x_train_1 = train_data.iloc[:, :-1]\n","    y_train_1 = train_data.iloc[:, -1]\n","    x_test_1 = test_data.iloc[:, :-1]\n","    y_test_1 = test_data.iloc[:, -1]\n","    xtrain1 = x_train_1.to_numpy()\n","    ytrain1 = y_train_1.to_numpy()\n","    xtest1 = x_test_1.to_numpy()\n","    ytest1 = y_test_1.to_numpy()\n","\n","    rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_1.fit(xtrain1, ytrain1)\n","    ypred1 = rf_1.predict(xtest1)\n","    fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","    c1 = auc(fpr1, tpr1)\n","\n","    # FGCRS\n","    train_data_2 = train_data.iloc[:, :16]\n","    train_label_2 = train_data.iloc[:, -1]\n","    test_data_2 = test_data.iloc[:, :16]\n","    test_label_2 = test_data.iloc[:, -1]\n","    train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","    test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","    x_train_2 = train_data_2.iloc[:, :-1]\n","    y_train_2 = train_data_2.iloc[:, -1]\n","    x_test_2 = test_data_2.iloc[:, :-1]\n","    y_test_2 = test_data_2.iloc[:, -1]\n","    xtrain2 = x_train_2.to_numpy()\n","    ytrain2 = y_train_2.to_numpy()\n","    xtest2 = x_test_2.to_numpy()\n","    ytest2 = y_test_2.to_numpy()\n","\n","    rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_2.fit(xtrain2, ytrain2)\n","    ypred2 = rf_2.predict(xtest2)\n","    fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","    c2 = auc(fpr2, tpr2)\n","\n","    #Delong Test\n","    p = delong_roc_test(ytest1,ypred1,ypred2)\n","    aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","    aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","    # Results\n","    c_table.loc[len(c_table)] = [c1, c2, p]\n","    col_name = disease.columns[1]\n","\n","\n","    arr_path = ('ypred1_'+f\"{col_name}_\" + str(j) +'.npy')\n","    np.save(arr_path, ypred1)\n","    arr_path = ('ypred2_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ypred2)\n","    arr_path = ('ytest_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"hXBLlgni2e88"},"source":["## Stratified Study (Genes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVAl5DDd2krx"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","path4='UKB多基因评分_ysp20230818.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","genes=pd.read_stata(path4)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a6','a16','a13','chol_mmol','hdl']] #education index\n","dm = dm[['eid_ageing','dmstatus']]\n","genes = genes[['eid_ageing','n_26285_0_0']]\n","convar = pd.merge(convar,genes, on='eid_ageing')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w2IXcrjS3BaR"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])\n","\n","cutoff_percentage = 0.5\n","convar = convar.dropna(subset=['n_26285_0_0'])\n","sorted_df = convar.sort_values(by='n_26285_0_0')\n","\n","total_count = len(sorted_df)\n","cutoff_index = int(total_count * cutoff_percentage)\n","sorted_df.loc[sorted_df.index[:cutoff_index], 'n_26285_0_0'] = 0\n","sorted_df.loc[sorted_df.index[cutoff_index:], 'n_26285_0_0'] = 1\n","result_df = sorted_df.sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XcvavxS3KsK"},"outputs":[],"source":["event = event[['eid_ageing','t2d_2104']] #,'mi_2104','cvd_hf_2104','cerestroke_2104','deathstatus','cvddeath_status'\n","c_table = pd.DataFrame(columns=['CB_CIL', 'CB_ROC', 'CB_CIH', 'CV_CIL', 'CV_ROC', 'CV_CIH', 'P'])\n","\n","for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(result_df,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  for j in range(2):\n","    gene = df_shuffled.loc[df_shuffled['n_26285_0_0'] == j]\n","    gene.drop(['n_26285_0_0'], axis=1, inplace=True)\n","\n","    train_ratio=0.8\n","    num_train_samples = int(len(gene) * train_ratio)\n","    train_data = gene[:num_train_samples].reset_index(drop=True)\n","    test_data = gene[num_train_samples:].reset_index(drop=True)\n","    train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","    test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","    # Combined Model\n","    age_idx = train_data.columns.get_loc('a1')\n","    x_train_1 = train_data.iloc[:, age_idx:-1]\n","    y_train_1 = train_data.iloc[:, -1]\n","    x_test_1 = test_data.iloc[:, age_idx:-1]\n","    y_test_1 = test_data.iloc[:, -1]\n","    xtrain1 = x_train_1.to_numpy()\n","    ytrain1 = y_train_1.to_numpy()\n","    xtest1 = x_test_1.to_numpy()\n","    ytest1 = y_test_1.to_numpy()\n","\n","    rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_1.fit(xtrain1, ytrain1)\n","    ypred1 = rf_1.predict(xtest1)\n","\n","    # FGCRS\n","    metab_idx = train_data.columns.get_loc('m7')\n","    train_data_2 = train_data.iloc[:, age_idx:metab_idx]\n","    train_label_2 = train_data.iloc[:, -1]\n","    test_data_2 = test_data.iloc[:, age_idx:metab_idx]\n","    test_label_2 = test_data.iloc[:, -1]\n","    train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","    test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","    x_train_2 = train_data_2.iloc[:, :-1]\n","    y_train_2 = train_data_2.iloc[:, -1]\n","    x_test_2 = test_data_2.iloc[:, :-1]\n","    y_test_2 = test_data_2.iloc[:, -1]\n","    xtrain2 = x_train_2.to_numpy()\n","    ytrain2 = y_train_2.to_numpy()\n","    xtest2 = x_test_2.to_numpy()\n","    ytest2 = y_test_2.to_numpy()\n","\n","    rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_2.fit(xtrain2, ytrain2)\n","    ypred2 = rf_2.predict(xtest2)\n","\n","    #Delong Test\n","    p = delong_roc_test(ytest1,ypred1,ypred2)\n","    aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","    aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","    # Results\n","    c_table.loc[len(c_table)] = [ci1[0], aus1, ci1[1], ci2[0], aus2, ci2[1], p[0,0]]\n","\n","    col_name = disease.columns[1]\n","\n","    arr_path = ('ypred1_'+f\"{col_name}_\" + str(j) +'.npy')\n","    np.save(arr_path, ypred1)\n","    arr_path = ('ypred2_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ypred2)\n","    arr_path = ('ytest_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('c_table_t2d.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"X0Wi66Ezj3-D"},"source":["## Stratified Study (Income)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcOrOs3Vj3-L"},"outputs":[],"source":["# Load data\n","path0='UKB协变量_ysp20230503.dta'\n","path1='UKB代谢组_ysp20230429.dta'\n","path2='UKB心血管结局_ysp20230429.dta'\n","path3='UKB_dmstatus.dta'\n","convar=pd.read_stata(path0)\n","metab=pd.read_stata(path1)\n","event=pd.read_stata(path2)\n","dm=pd.read_stata(path3)\n","\n","metab = metab[['eid_ageing','m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']]\n","convar = convar[['eid_ageing','a1','a2','a4','a6','a16','a13','chol_mmol','hdl']] # a4: average total household income before tax\n","dm = dm[['eid_ageing','dmstatus']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_GCJPmkdj3-L"},"outputs":[],"source":["# normalization\n","scaler = MinMaxScaler()\n","columns_to_normalize=['a1','a16','chol_mmol','hdl']\n","convar[columns_to_normalize] = scaler.fit_transform(convar[columns_to_normalize])\n","columns_to_normalize = ['m7','m12','m15','m19','m23','m27','m28','m31','m35','m36','m37','m40','m154','m155','m156','m157','m158','m159','m161','m162','m163','m164','m165','m166','m205','m210']\n","metab[columns_to_normalize] = scaler.fit_transform(metab[columns_to_normalize])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3Iaq3_Uj3-L"},"outputs":[],"source":["event = event[['eid_ageing','deathstatus','cvd_hf_2104','cerestroke_2104','t2d_2104','mi_2104','cvddeath_status']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5lEqjrVj3-L"},"outputs":[],"source":["c_table = pd.DataFrame(columns=['RF_CB', 'RF_FGCRS','P-value'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEABJXtMj3-M"},"outputs":[],"source":["for i in tqdm(range(event.shape[1]-1)):\n","\n","  disease =  event.iloc[:, [0,i+1]]\n","  merged_df = pd.merge(metab,disease, on='eid_ageing')\n","  merged_df = pd.merge(dm,merged_df, on='eid_ageing')\n","  merged_df = pd.merge(convar,merged_df, on='eid_ageing')\n","  merged_df = merged_df.dropna()\n","  df_shuffled = merged_df.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  for j in range(2):\n","    townsend = df_shuffled.loc[df_shuffled['a4'] == j]\n","    townsend.drop(['a4'], axis=1, inplace=True)\n","\n","    train_ratio=0.8\n","    test_ratio=0.2\n","    num_train_samples = int(len(townsend) * train_ratio)\n","    num_test_samples = len(townsend) - num_train_samples\n","    train_data = townsend[:num_train_samples].reset_index(drop=True)\n","    test_data = townsend[num_train_samples:].reset_index(drop=True)\n","    train_data.drop(['eid_ageing'], axis=1, inplace=True)\n","    test_data.drop(['eid_ageing'], axis=1, inplace=True)\n","\n","    # Combined Model\n","    x_train_1 = train_data.iloc[:, :-1]\n","    y_train_1 = train_data.iloc[:, -1]\n","    x_test_1 = test_data.iloc[:, :-1]\n","    y_test_1 = test_data.iloc[:, -1]\n","    xtrain1 = x_train_1.to_numpy()\n","    ytrain1 = y_train_1.to_numpy()\n","    xtest1 = x_test_1.to_numpy()\n","    ytest1 = y_test_1.to_numpy()\n","\n","    rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_1.fit(xtrain1, ytrain1)\n","    ypred1 = rf_1.predict(xtest1)\n","    fpr1, tpr1, _ = roc_curve(ytest1, ypred1)\n","    c1 = auc(fpr1, tpr1)\n","\n","    # FGCRS\n","    train_data_2 = train_data.iloc[:, :16]\n","    train_label_2 = train_data.iloc[:, -1]\n","    test_data_2 = test_data.iloc[:, :16]\n","    test_label_2 = test_data.iloc[:, -1]\n","    train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","    test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","    x_train_2 = train_data_2.iloc[:, :-1]\n","    y_train_2 = train_data_2.iloc[:, -1]\n","    x_test_2 = test_data_2.iloc[:, :-1]\n","    y_test_2 = test_data_2.iloc[:, -1]\n","    xtrain2 = x_train_2.to_numpy()\n","    ytrain2 = y_train_2.to_numpy()\n","    xtest2 = x_test_2.to_numpy()\n","    ytest2 = y_test_2.to_numpy()\n","\n","    rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","    rf_2.fit(xtrain2, ytrain2)\n","    ypred2 = rf_2.predict(xtest2)\n","    fpr2, tpr2, _ = roc_curve(ytest2, ypred2)\n","    c2 = auc(fpr2, tpr2)\n","\n","    #Delong Test\n","    p = delong_roc_test(ytest1,ypred1,ypred2)\n","    aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","    aus2,ci2 = delong_roc_ci(ytest1,ypred2)\n","\n","    # Results\n","    c_table.loc[len(c_table)] = [c1, c2, p]\n","    col_name = disease.columns[1]\n","\n","\n","    arr_path = ('ypred1_'+f\"{col_name}_\" + str(j) +'.npy')\n","    np.save(arr_path, ypred1)\n","    arr_path = ('ypred2_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ypred2)\n","    arr_path = ('ytest_'+f\"{col_name}_\" + str(j)+'.npy')\n","    np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('syndata/c_table.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"Ck-uXaMOEOUR"},"source":["## Synthetic data analysis"]},{"cell_type":"markdown","metadata":{"id":"8FiW13TTeQbw"},"source":["### Comparison of individual predictors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GLiUsXuf1MT"},"outputs":[],"source":["path = 'data/Sample Data.csv'\n","synthetic_data = pd.read_csv(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"czV8SJ_LEQqY"},"outputs":[],"source":["event = 'cvd'\n","\n","convar=['age', 'sex', 'smoker', 'dmduration', 'y0_sbp','y0_dbp','y0_hba1c','y0_chol','y0_hdlc', 'egfr_y0', 'med_insulin','bmi','rnfl']\n","\n","c_table = pd.DataFrame(columns=['CIL', 'ROC', 'CIH'])\n","\n","for i in tqdm(range(len(convar))):\n","  df_shuffled = synthetic_data.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","\n","  if i<len(convar)-1:\n","      idx = train_data.columns.get_loc(convar[i])\n","      x_train_1 = train_data.iloc[:, idx]\n","      y_train_1 = train_data.iloc[:, -1]\n","      x_test_1 = test_data.iloc[:, idx]\n","      y_test_1 = test_data.iloc[:, -1]\n","      xtrain1 = x_train_1.to_numpy()\n","      ytrain1 = y_train_1.to_numpy()\n","      xtest1 = x_test_1.to_numpy()\n","      ytest1 = y_test_1.to_numpy()\n","\n","      xtrain1=xtrain1.reshape(-1, 1)\n","      xtest1=xtest1.reshape(-1, 1)\n","\n","  else:\n","      idx = train_data.columns.get_loc('m1')\n","      x_train_1 = train_data.iloc[:, idx:-1]\n","      y_train_1 = train_data.iloc[:, -1]\n","      x_test_1 = test_data.iloc[:, idx:-1]\n","      y_test_1 = test_data.iloc[:, -1]\n","      xtrain1 = x_train_1.to_numpy()\n","      ytrain1 = y_train_1.to_numpy()\n","      xtest1 = x_test_1.to_numpy()\n","      ytest1 = y_test_1.to_numpy()\n","\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","\n","  # Results\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","\n","  c_table.loc[len(c_table)] = [ci1[0], aus1, ci1[1]]\n","\n","  arr_path = ('syndata/pred/ypred1_'+f'{convar[i]}'+'.npy')\n","  np.save(arr_path, ypred1)\n","\n","  arr_path = ('syndata/pred/ytest_'+f'{convar[i]}'+'.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('syndata/singleconv_roctable.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"FdZ-M4jWehef"},"source":["### Comparison of model performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mERTUtzoeqA0"},"outputs":[],"source":["def prepare_model_data(synthetic_data, model_name):\n","\n","    if model_name == 'AgeSex':\n","        #AgeSex model\n","        conv_cols = ['age', 'sex']\n","    elif model_name == 'FGCRS':\n","        #FGCRS model\n","        conv_cols = ['age', 'sex', 'smoker', 'y0_sbp', 'med_hpt', 'y0_chol', 'y0_hdlc', 'dmduration']\n","    elif model_name == 'UKPDS':\n","        #UKPDS model\n","        conv_cols = ['age', 'sex', 'smoker', 'y0_hba1c', 'y0_sbp', 'y0_chol', 'y0_hdlc']\n","    elif model_name == 'Wan':\n","        #Wan model\n","        conv_cols = ['age', 'sex', 'dmduration', 'bmi', 'y0_sbp', 'y0_dbp', 'y0_hba1c',\n","                     'y0_chol', 'y0_hdlc', 'egfr_y0', 'med_hpt', 'med_insulin']\n","    elif model_name == 'DCS':\n","        #DCS model\n","        conv_cols = ['age', 'sex', 'dmduration', 'smoker', 'y0_sbp', 'y0_hba1c',\n","                     'y0_chol', 'y0_hdlc']\n","    else:\n","        raise ValueError(f\"Unknown model name: {model_name}\")\n","\n","    convar = synthetic_data[conv_cols].copy()\n","\n","    metab_idx = synthetic_data.columns.get_loc('m1')\n","    metab_cols = synthetic_data.iloc[:, metab_idx:]\n","\n","    merged_data = pd.concat([convar, metab_cols], axis=1)\n","\n","    return merged_data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCSj9kEEeyad"},"outputs":[],"source":["models = ['AgeSex', 'FGCRS', 'UKPDS', 'Wan', 'DCS']\n","c_table = pd.DataFrame(columns=['CB_CIL', 'CB_ROC', 'CB_CIH', 'CV_CIL', 'CV_ROC', 'CV_CIH', 'P'])\n","\n","for i in tqdm(range(len(models))):\n","  model = models[i]\n","  merged_data = prepare_model_data(synthetic_data, model)\n","  df_shuffled = merged_data.sample(frac=1,random_state=100).reset_index(drop=True)\n","\n","  train_ratio=0.8\n","  num_train_samples = int(len(df_shuffled) * train_ratio)\n","  num_test_samples = len(df_shuffled) - num_train_samples\n","  train_data = df_shuffled[:num_train_samples].reset_index(drop=True)\n","  test_data = df_shuffled[num_train_samples:].reset_index(drop=True)\n","\n","  # Combined Model\n","  age_idx = train_data.columns.get_loc('age')\n","  x_train_1 = train_data.iloc[:, age_idx:-1]\n","  y_train_1 = train_data.iloc[:, -1]\n","  x_test_1 = test_data.iloc[:, age_idx:-1]\n","  y_test_1 = test_data.iloc[:, -1]\n","  xtrain1 = x_train_1.to_numpy()\n","  ytrain1 = y_train_1.to_numpy()\n","  xtest1 = x_test_1.to_numpy()\n","  ytest1 = y_test_1.to_numpy()\n","\n","  rf_1 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_1.fit(xtrain1, ytrain1)\n","  ypred1 = rf_1.predict(xtest1)\n","\n","  # clinical model\n","  metab_idx = train_data.columns.get_loc('m1')\n","  train_data_2 = train_data.iloc[:, age_idx:metab_idx]\n","  train_label_2 = train_data.iloc[:, -1]\n","  test_data_2 = test_data.iloc[:, age_idx:metab_idx]\n","  test_label_2 = test_data.iloc[:, -1]\n","  train_data_2 = pd.concat([train_data_2, train_label_2], axis=1)\n","  test_data_2 = pd.concat([test_data_2, test_label_2], axis=1)\n","\n","  x_train_2 = train_data_2.iloc[:, :-1]\n","  y_train_2 = train_data_2.iloc[:, -1]\n","  x_test_2 = test_data_2.iloc[:, :-1]\n","  y_test_2 = test_data_2.iloc[:, -1]\n","  xtrain2 = x_train_2.to_numpy()\n","  ytrain2 = y_train_2.to_numpy()\n","  xtest2 = x_test_2.to_numpy()\n","  ytest2 = y_test_2.to_numpy()\n","\n","  rf_2 = RandomForestRegressor(n_estimators=200, max_depth=10, oob_score=True, random_state = 100)\n","  rf_2.fit(xtrain2, ytrain2)\n","  ypred2 = rf_2.predict(xtest2)\n","\n","  # Results\n","  p = delong_roc_test(ytest1,ypred1,ypred2)\n","  aus1,ci1 = delong_roc_ci(ytest1,ypred1)\n","  aus2,ci2 = delong_roc_ci(ytest2,ypred2)\n","\n","  c_table.loc[len(c_table)] = [ci1[0], aus1, ci1[1], ci2[0], aus2, ci2[1], p[0,0]]\n","\n","  arr_path = ('syndata/models/'+f'{model}'+'_ypred1.npy')\n","  np.save(arr_path, ypred1)\n","  arr_path = ('syndata/models/'+f'{model}'+'_ypred2.npy')\n","  np.save(arr_path, ypred2)\n","  arr_path = ('syndata/models/'+f'{model}'+'_ytest.npy')\n","  np.save(arr_path, ytest1)\n","\n","# Save table file\n","c_table.to_csv('syndata/models_roctable.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}